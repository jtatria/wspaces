% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{weight_tfidf}
\alias{weight_tfidf}
\title{TF-IDF weighting.}
\usage{
weight_tfidf(tf_, df_, tf_mode = 2L, idf_mode = 2L, ow = FALSE)
}
\arguments{
\item{tf_}{A matrix with one row for each term, and as many columns as documents or corpus
segments there are frequencies for.}

\item{df_}{A vector of length equal the number of rows in tf_, containing document
frequencies, to compute the IDF component.}

\item{tf_mode}{A term frequency weigthing strategy. See details.}

\item{idf_mode}{An inverse document frequency weigthing strategy. See details.}

\item{ow}{A logical vector indicating whether the result should be destructively copied
over the input matrix.}
}
\value{
An isomorphic matrix to tf_, with entries weighted by the given strategy. If ow == TRUE,
       tf_ is replaced with this value.
}
\description{
Weigth the given frequency matrix using the TF-IDF stategy.
}
\details{
TF-IDF weights attempt to moderate the effect of very common terms, by dividing the total
frequency of a term within a context (i.e. a document, but in general any corpus segment),
by the number of contexts in which the term appears.

The idea behind this approach is that terms that appear in every possible context do not
provide any additional information to the contexts in which they appear. Hence, all TF-IDF
strategies compute weights as some variation of \eqn{TF_{t,c} / IDF_{t}}, where
\eqn{TF_{t,c}} is a monotonic function of a term t's prevalence within a specific context
c and \eqn{IDF_{t}} is an inversely monotonic function of the term t's prevalence in all
contexts across the entire corpus.

Note that the TF term is valid for a term in a context, while the IDF term is valid for a
term across the entire corpus.

Values of tf_mode and idf_mode indicate how the TF and IDF terms are computed, as indicated
below.

\itemize{
  \item{TF modes}
  \itemize{
    \item{0: Boolean: 1 if tf > 0; 0 otherwise.}
    \item{1: Raw: Raw term frequency.}
    \item{2: Normalized: (default) Term frequency divided by the total number of terms
             in document (the 'length').}
    \item{3: Log-normlized: Natural log of the term frequency over total document
             terms, + 1.}
    \item{4: 0.5 normalized: K*(1-K) * (tf / max( tf ) ), with K set to 0.5.}
  }
  \item{IDF modes}
  \itemize{
    \item{0: Unary: 1 if df > 0, but terms with 0 DF are by definition excluded of the
             lexicon, so 1.}
    \item{1: Plain: log of total number of documents, D, over the term's df.}
    \item{2: Smooth: (default) log of total number of documents, D, over the term's df,
             plus 1.}
    \item{3: Max: log of maximum df, over the term's df.}
    \item{4: Probabilistic: log of the total number of documents minus the term's df
             over the term's df.}
  }
}
}
